{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#1119.py\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faceCascade= cv2.CascadeClassifier(\n",
    "      './image/haarcascade_frontalface_default.xml')\n",
    "eyeCascade = cv2.CascadeClassifier(\n",
    "    './image/haarcascade_eye.xml')\n",
    "\n",
    "src = cv2.imread('./image/jang.jpg')\n",
    "gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "faces = faceCascade.detectMultiScale(gray, 1.1, 2) #(gray, 1.1, 0)\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(src, (x,y),(x+w, y+h),(255,0,0), 2)\n",
    "    \n",
    "    roi_gray  = gray[y:y+h, x:x+w]\n",
    "    roi_color = src[y:y+h, x:x+w]\n",
    "    \n",
    "eyes = eyeCascade.detectMultiScale(roi_gray)\n",
    "for (ex,ey,ew,eh) in eyes:\n",
    "    cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "        \n",
    "cv2.imshow('src', src)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(eyes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, pafy\n",
    "\n",
    "faceCascade= cv2.CascadeClassifier(\n",
    "      './image/haarcascade_frontalface_default.xml')\n",
    "url = 'https://www.youtube.com/watch?v=-VLquFsP3pU'\n",
    "video = pafy.new(url)\n",
    "best = video.getbest(preftype='webm')\n",
    "\n",
    "cap=cv2.VideoCapture(best.url)\n",
    "while(True):\n",
    "        retval, frame = cap.read()\n",
    "        if not retval:\n",
    "                break\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        faces = faceCascade.detectMultiScale(gray) #minSize=(50, 50)\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x,y),(x+w, y+h),(255,0,0), 2)           \n",
    "        cv2.imshow('frame',frame)\n",
    " \n",
    "        key = cv2.waitKey(25)\n",
    "        if key == 27: # Esc\n",
    "                break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #numpy를 설치하지 않았다면 'pip install numpy'\n",
    "import cv2, pafy #opencv2설치 명령어는 게시글 참고. pafy는 'pip install pafy'\n",
    "\n",
    "faceCascade=cv2.CascadeClassifier('./image/haarcascade_frontalface_default.xml')\n",
    "\n",
    "url = 'https://www.youtube.com/watch?v=-VLquFsP3pU'\n",
    "video = pafy.new(url)\n",
    "\n",
    "print('title = ', video.title) #영상의 제목을 표시.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(video.rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(video.author, video.length) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = video.getbest() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('best.resolution', best.resolution) #영상의 크기를 표시."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cap = cv2.VideoCapture(best.url)\n",
    "while(True):\n",
    "     retval, frame = cap.read()\n",
    "     if not retval:\n",
    "            break\n",
    "     gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "     faces = faceCascade.detectMultiScale(gray)   #minSize = (50,50)\n",
    "     for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 1)\n",
    "     cv2.imshow('frame', frame)\n",
    "\n",
    "     key = cv2.waitKey(25)\n",
    "     if key == 27:   #Esc누르면 종료. x키 열심히 눌러도 소용없음. Esc를 눌러야함.\n",
    "            break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "faceCascade=cv2.CascadeClassifier('./image/haarcascade_frontalface_default.xml')\n",
    "eyeCascade=cv2.CascadeClassifier('./image/haarcascade_eye.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "\n",
    "print('width :%d, height : %d' % (cap.get(3), cap.get(4)))\n",
    "while(True):\n",
    "    ret, frame = cap.read()    # Read 결과와 frame\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)    \n",
    "    eyes = eyeCascade.detectMultiScale(gray)\n",
    "    faces = faceCascade.detectMultiScale(gray)\n",
    "    if(ret) :\n",
    "        gray = cv2.cvtColor(frame,  cv2.COLOR_BGR2GRAY)    # 입력 받은 화면 Gray로 변환\n",
    "        for (x, y, w, h) in eyes:\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 4)\n",
    "            \n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 3)\n",
    "            \n",
    "        #cv2.imshow('frame_gray', gray)    # Gray 화면 출력\n",
    "        cv2.imshow('frame_color', frame)    # 컬러 화면 출력\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "faceCascade=cv2.CascadeClassifier('./image/haarcascade_frontalface_default.xml')\n",
    "eyeCascade=cv2.CascadeClassifier('./image/haarcascade_eye.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "print('width :%d, height : %d' % (cap.get(3), cap.get(4)))\n",
    "while(True):\n",
    "    ret, frame = cap.read()    # Read 결과와 frame\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)    \n",
    "    eyes = eyeCascade.detectMultiScale(gray)\n",
    "    faces = faceCascade.detectMultiScale(gray)\n",
    "    if(ret) :\n",
    "        \n",
    "        gray = cv2.cvtColor(frame,  cv2.COLOR_BGR2GRAY)    # 입력 받은 화면 Gray로 변환\n",
    "#         for (x, y, w, h) in eyes:\n",
    "#             cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 4)\n",
    "            \n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x-10, y-10), (x + w+10, y + h+10), (0, 0, 255), 5)\n",
    "#             time.sleep(0.5)    \n",
    "        #cv2.imshow('frame_gray', gray)    # Gray 화면 출력\n",
    "        cv2.imshow('frame_color', frame)    # 컬러 화면 출력\n",
    "        \n",
    "#         if cv2.waitKey(1) == ord('q') and faces == 1:\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "cv2.imwrite(\"C:/Users/rlawk/PycharmProjects/pythonProject/target.jpg\",frame)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "frame = cv2.imread(\"./image/source.jpg\")\n",
    "cv2.imwrite(\"C:/Users/rlawk/PycharmProjects/pythonProject/target.jpg\",frame)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###faces의 배열수를 찾아서 얼굴인식후 종료\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "width :640, height : 480\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "faceCascade=cv2.CascadeClassifier('./image/haarcascade_frontalface_default.xml')\n",
    "eyeCascade=cv2.CascadeClassifier('./image/haarcascade_eye.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "print('width :%d, height : %d' % (cap.get(3), cap.get(4)))\n",
    "while(True):\n",
    "    ret, frame = cap.read()    # Read 결과와 frame\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)    \n",
    "    eyes = eyeCascade.detectMultiScale(gray)\n",
    "    faces = faceCascade.detectMultiScale(gray)\n",
    "    \n",
    "    if(ret) :\n",
    "        \n",
    "#         gray = cv2.cvtColor(frame,  cv2.COLOR_BGR2GRAY)    # 입력 받은 화면 Gray로 변환\n",
    "#         for (x, y, w, h) in eyes:\n",
    "#             cv2.rectangle(gray, (x, y), (x + w, y + h), (255, 0, 0), 4)\n",
    "            \n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x-10, y-10), (x + w+10, y + h+10), (0, 0, 255), 5)\n",
    "#         cv2.imshow('frame_gray', gray)    # Gray 화면 출력\n",
    "        cv2.imshow('frame_color', frame)    # 컬러 화면 출력\n",
    "        \n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "    if len(faces)>=2:\n",
    "        break        \n",
    "cv2.imwrite(\"C:/Users/rlawk/PycharmProjects/pythonProject/target.jpg\",frame)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "width :640, height : 480\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "faceCascade=cv2.CascadeClassifier('./image/haarcascade_frontalface_default.xml')\n",
    "eyeCascade=cv2.CascadeClassifier('./image/haarcascade_eye.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "print('width :%d, height : %d' % (cap.get(3), cap.get(4)))\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cap.read()    # Read 결과와 frame\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)    \n",
    "    eyes = eyeCascade.detectMultiScale(gray)\n",
    "    faces = faceCascade.detectMultiScale(gray)\n",
    "    \n",
    "    if(ret) :\n",
    "                    \n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x-6, y-6), (x + w+6 ,y + h+6), (0, 0, 255), 5)\n",
    "\n",
    "        cv2.imshow('frame_color', frame)    # 컬러 화면 출력\n",
    "        \n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "    if len(faces)>=1:\n",
    "        break        \n",
    "cv2.imwrite(\"C:/Users/rlawk/PycharmProjects/pythonProject/target.jpg\",frame)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "###검출한 사람 썸네일저장\n",
    "img = cv2.imread(\"C:/Users/rlawk/PycharmProjects/pythonProject/target.jpg\")\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = faceCascade.detectMultiScale(gray)\n",
    "imgNum  = 0\n",
    "for (x,y,w,h) in faces:\n",
    "    cropped = img[y - int(h / 4):y + h + int(h / 4), x - int(w / 4):x + w + int(w / 4)]\n",
    "    # 이미지를 저장\n",
    "    cv2.imwrite(\"C:/Users/rlawk/PycharmProjects/pythonProject/thumbnail\" + str(imgNum) + \".png\", cropped)\n",
    "    imgNum += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
